"""Run Sugarscape experiments with different LLM agent goals to study their impact on welfare metrics."""

import sys
import os
import argparse
from pathlib import Path

# Add project root to path
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

from redblackbench.sugarscape.simulation import SugarSimulation
from redblackbench.sugarscape.config import SugarscapeConfig

# Default model paths
QWEN3_14B_BASE = "/workspace/models/Qwen3-14B"
QWEN3_14B_LORA = "/workspace/models/Qwen3-14B-LoRA"  # For fine-tuned experiments


def run_goal_experiment(goal_preset: str, ticks: int = 100, seed: int = 42,
                       model: str = QWEN3_14B_BASE,
                       population: int = 100, width: int = 30, height: int = 30,
                       difficulty: str = "standard", trade_rounds: int = 4,
                       provider: str = "vllm", use_lora: bool = False,
                       use_mixed_identity: bool = False,
                       identity_distribution: dict = None,
                       enable_survival_pressure: bool = True,
                       social_memory_visible: bool = True,
                       trust_mechanism_mode: str = "hybrid",
                       enable_abstraction_prompt: bool = False,
                       encounter_protocol_mode: str = "full",
                       experiment_name_suffix: str = "",
                       # LLM Evaluation options
                       enable_llm_evaluation: bool = True,
                       llm_evaluator_model: str = "openai/gpt-4o-mini",
                       llm_evaluator_provider: str = "openrouter",
                       # Resource abundance options
                       initial_wealth_min: int = None,
                       initial_wealth_max: int = None,
                       growback_rate: int = None):
    """Run a single experiment with a specific goal preset.
    
    Ablation flags:
        enable_survival_pressure: If False, agents don't die from starvation (only old age)
        social_memory_visible: If False, agents can't see trade history or partner reputation
    """

    print(f"\n{'='*60}")
    print(f"Running Goal Experiment: {goal_preset.upper()}")
    print(f"{'='*60}")

    # Use LoRA model if specified
    if use_lora:
        model = QWEN3_14B_LORA
        print(f"Using LoRA fine-tuned model: {model}")

    # Configure simulation
    config = SugarscapeConfig(
        initial_population=population,
        max_ticks=ticks,
        width=width,
        height=height,
        seed=seed,
        enable_llm_agents=True,
        llm_agent_ratio=1.0,  # All agents are LLM
        llm_provider_type=provider,
        llm_provider_model=model,
        llm_goal_preset=goal_preset,
        enable_spice=True,
        enable_trade=True,  # Enable trade for goal experiments
        trade_dialogue_rounds=trade_rounds,
        # Trade robustness features to reduce timeouts
        trade_dialogue_repair_json=True,
        trade_dialogue_repair_attempts=2,
        trade_dialogue_coerce_protocol=True,  # Force valid actions to prevent timeouts
        trade_dialogue_two_stage=True,
        # Explicitly enable small talk and new encounter protocol
        enable_new_encounter_protocol=True,
        small_talk_rounds=2,
        # Ablation flags
        enable_survival_pressure=enable_survival_pressure,
        social_memory_visible=social_memory_visible,
        trust_mechanism_mode=trust_mechanism_mode,
        enable_abstraction_prompt=enable_abstraction_prompt,
        encounter_protocol_mode=encounter_protocol_mode,
        # LLM Evaluation settings
        enable_llm_evaluation=enable_llm_evaluation,
        llm_evaluator_model=llm_evaluator_model,
        llm_evaluator_provider=llm_evaluator_provider,
    )

    # Print ablation status
    if not enable_survival_pressure:
        print("⚠️ ABLATION: Survival pressure DISABLED (agents won't die from starvation)")
    if not social_memory_visible:
        print("⚠️ ABLATION: Social memory DISABLED (no trade history, reputation hidden)")
    elif trust_mechanism_mode != "hybrid":
        print(f"⚠️ ABLATION: Trust mechanism mode = {trust_mechanism_mode}")
    if enable_abstraction_prompt:
        print("⚠️ ABLATION: Abstraction prompt ENABLED (encouraging abstract principles)")
    if encounter_protocol_mode != "full":
        print(f"⚠️ ABLATION: Encounter protocol mode = {encounter_protocol_mode}")
    
    # Print evaluation status
    if enable_llm_evaluation:
        print(f"✓ LLM Evaluation ENABLED (model: {llm_evaluator_model})")
    else:
        print("⚠️ LLM Evaluation DISABLED (behavioral metrics only)")

    if use_mixed_identity or identity_distribution:
        config.enable_origin_identity = True
        if identity_distribution:
            config.origin_identity_distribution = identity_distribution
            dist_str = ", ".join(f"{k}: {v*100:.0f}%" for k, v in identity_distribution.items())
            print(f"Enabled Origin Identity System ({dist_str})")
        else:
            # Default distribution
            print("Enabled Origin Identity System (80% Exploiter / 20% Altruist)")

    # Apply difficulty preset
    if difficulty == "easy":
        config.sugar_growback_rate = 2
        config.max_sugar_capacity = 6
        config.spice_growback_rate = 2
        config.max_spice_capacity = 6
    elif difficulty == "harsh":
        config.sugar_growback_rate = 1
        config.max_sugar_capacity = 2
        config.spice_growback_rate = 1
        config.max_spice_capacity = 2
    elif difficulty == "desert":
        config.sugar_growback_rate = 0
        config.max_sugar_capacity = 4
        config.spice_growback_rate = 0
        config.max_spice_capacity = 4

    # Override resource settings if specified
    if initial_wealth_min is not None and initial_wealth_max is not None:
        config.initial_wealth_range = (initial_wealth_min, initial_wealth_max)
        config.initial_spice_range = (initial_wealth_min, initial_wealth_max)
        print(f"✓ Initial resources: {initial_wealth_min}-{initial_wealth_max} (sugar & spice)")
    
    if growback_rate is not None:
        config.sugar_growback_rate = growback_rate
        config.spice_growback_rate = growback_rate
        config.max_sugar_capacity = max(6, growback_rate * 2)  # Scale capacity with rate
        config.max_spice_capacity = max(6, growback_rate * 2)
        print(f"✓ Growback rate: {growback_rate} (capacity: {config.max_sugar_capacity})")

    print(f"Goal: {goal_preset}")
    print(f"Goal Prompt: {config.llm_goal_prompt[:100]}...")
    print(f"Grid: {width}x{height} ({width*height} cells)")
    print(f"Population: {population} agents ({population/(width*height)*100:.1f}% density)")
    print(f"Seed: {seed}, Ticks: {ticks}")

    exp_name = f"goal_{goal_preset}"
    if experiment_name_suffix:
        exp_name += f"_{experiment_name_suffix}"
    sim = SugarSimulation(config=config, experiment_name=exp_name)

    print("\nInitial Stats:")
    initial_stats = sim.get_stats()
    print(f"  Population: {initial_stats['population']}")
    print(f"  Mean Wealth: {initial_stats['mean_wealth']:.2f}")
    print(f"  Survival Rate: {initial_stats['survival_rate']:.2f}")

    print("\nRunning simulation...")
    sim.run(steps=ticks)

    print("\nFinal Stats:")
    final_stats = sim.get_stats()
    print(f"  Population: {final_stats['population']}")
    print(f"  Mean Wealth: {final_stats['mean_wealth']:.2f}")
    print(f"  Survival Rate: {final_stats['survival_rate']:.2f}")
    print(f"  Utilitarian Welfare: {final_stats['utilitarian_welfare']:.2f}")
    print(f"  Nash Welfare: {final_stats['nash_welfare']:.2f}")
    print(f"  Rawlsian Welfare: {final_stats['rawlsian_welfare']:.2f}")
    print(f"  Welfare Gini: {final_stats['welfare_gini']:.3f}")
    print(f"  Mean Lifespan Utilization: {final_stats['mean_lifespan_utilization']:.3f}")

    # Print reputation stats
    if hasattr(sim.env, 'agent_reputation') and sim.env.agent_reputation:
        reps = list(sim.env.agent_reputation.values())
        print(f"\nReputation Stats:")
        print(f"  Mean Reputation: {sum(reps)/len(reps):.3f}")
        print(f"  Min Reputation: {min(reps):.3f}")
        print(f"  Max Reputation: {max(reps):.3f}")

    return sim.logger.run_dir, final_stats


def compare_goals(goals_to_test, ticks=100, seed=42, model=QWEN3_14B_BASE,
                  population=100, width=30, height=30, difficulty="standard",
                  trade_rounds=4, provider="vllm", use_lora=False):
    """Run experiments with multiple goal presets and compare results."""

    results = {}

    print(f"\n{'='*80}")
    print("GOAL COMPARISON EXPERIMENT")
    print(f"{'='*80}")
    print(f"Testing {len(goals_to_test)} goal presets with {ticks} ticks, seed={seed}")

    for goal in goals_to_test:
        try:
            run_dir, final_stats = run_goal_experiment(
                goal, ticks, seed, model, population, width, height,
                difficulty, trade_rounds, provider, use_lora
            )
            results[goal] = {
                'run_dir': run_dir,
                'final_stats': final_stats
            }
        except Exception as e:
            print(f"Error running {goal}: {e}")
            continue

    # Print comparison summary
    print(f"\n{'='*80}")
    print("COMPARISON SUMMARY")
    print(f"{'='*80}")

    print(f"{'Goal':<12}{'Pop':>8}{'Welfare':>12}{'Nash':>12}{'Gini':>12}")
    print("-" * 80)

    for goal, data in results.items():
        stats = data['final_stats']
        print(f"{goal:<12}{stats['population']:>8}{stats['utilitarian_welfare']:>12.2f}"
              f"{stats['nash_welfare']:>12.2f}{stats['welfare_gini']:>12.3f}")

    print("-" * 80)

    # Generate comparison plots if we have multiple results
    if len(results) >= 2:
        print("\nGenerating comparison plots...")

        # Create comparison directory
        try:
            from redblackbench.sugarscape.welfare_plots import WelfarePlotter
        except ImportError:
            print("Warning: Matplotlib not available. Skipping plot generation.")
            return results

        comparison_dir = Path("results/sugarscape/goal_comparison")
        comparison_dir.mkdir(parents=True, exist_ok=True)

        # Get CSV paths for the first two goals (or more if desired)
        csv_paths = []
        goal_names = []
        for goal, data in list(results.items())[:4]:  # Compare up to 4 goals
            csv_path = Path(data['run_dir']) / "metrics.csv"
            if csv_path.exists():
                csv_paths.append(str(csv_path))
                goal_names.append(goal)

        if len(csv_paths) >= 2:
            WelfarePlotter.generate_comparison_plots(
                llm_csv_path=csv_paths[0],
                baseline_csv_path=csv_paths[1],
                output_dir=str(comparison_dir)
            )

            print(f"Comparison plots saved to: {comparison_dir}")

    return results


def parse_args():
    parser = argparse.ArgumentParser(description="Run Sugarscape Goal Experiments")

    parser.add_argument("--goals", nargs="+",
                        choices=["none", "survival", "wealth", "altruist"],
                        default=["none", "survival", "wealth", "altruist"],
                        help="Goal presets to test (altruist = merged egalitarian/utilitarian/samaritan)")

    parser.add_argument("--ticks", type=int, default=100,
                        help="Number of simulation ticks (default: 100)")

    parser.add_argument("--population", type=int, default=100,
                        help="Initial population size (default: 100)")

    parser.add_argument("--width", type=int, default=30,
                        help="Grid width (default: 30)")
    parser.add_argument("--height", type=int, default=30,
                        help="Grid height (default: 30)")

    parser.add_argument("--difficulty", type=str, choices=["standard", "easy", "harsh", "desert"],
                        default="standard", help="Difficulty preset")

    parser.add_argument("--trade-rounds", type=int, default=4,
                        help="Maximum dialogue rounds during trade negotiations (default: 4)")

    parser.add_argument("--seed", type=int, default=42,
                        help="Random seed for reproducibility")

    parser.add_argument("--single", type=str,
                        choices=["none", "survival", "wealth", "altruist"],
                        help="Run single goal experiment (overrides --goals)")

    parser.add_argument("--provider", type=str, choices=["openrouter", "vllm"],
                        default="vllm", help="LLM provider to use (default: vllm)")

    parser.add_argument("--model", type=str, default=QWEN3_14B_BASE,
                        help=f"Model path for vLLM (default: {QWEN3_14B_BASE})")

    parser.add_argument("--lora", action="store_true",
                        help="Use LoRA fine-tuned model instead of base model")

    parser.add_argument("--use-mixed-identity", action="store_true",
                        help="Enable mixed origin identity (80% Exploiter, 20% Altruist)")

    parser.add_argument("--identity-distribution", type=str, default=None,
                        help="Custom identity distribution as 'type1:pct,type2:pct,...' "
                             "e.g., 'altruist:20,survivor:80' or 'altruist:20,exploiter:60,survivor:20'. "
                             "Types: altruist, exploiter, survivor")

    parser.add_argument("--smoke-test", action="store_true",
                        help="Quick smoke test: 5 ticks, 10 agents on 10x10 grid")

    # Ablation study flags
    parser.add_argument("--no-survival-pressure", action="store_true",
                        help="ABLATION: Disable survival pressure (agents don't die from starvation)")
    parser.add_argument("--no-social-memory", action="store_true",
                        help="ABLATION: Disable social memory (no trade history, reputation hidden)")
    parser.add_argument("--no-global-reputation", action="store_true",
                        help="ABLATION: Disable GLOBAL reputation (keep personal memory/trust only)")
    parser.add_argument("--trust-mechanism-mode", type=str, default="hybrid",
                        choices=["hybrid", "personal_only", "global_only"],
                        help="ABLATION: Trust mechanism mode (hybrid=public+personal, personal_only=no public rep, global_only=no personal memory)")
    parser.add_argument("--enable-abstraction-prompt", action="store_true",
                        help="ABLATION: Add explicit prompt encouraging abstract principle formation")
    parser.add_argument("--encounter-protocol-mode", type=str, default="full",
                        choices=["full", "chat_only", "protocol_only"],
                        help="ABLATION: Encounter protocol mode (full=normal, chat_only=no trade, protocol_only=no speech)")
    parser.add_argument("--experiment-suffix", type=str, default="",
                        help="Suffix to add to experiment name (for ablation labeling)")
    
    # LLM Evaluation options
    parser.add_argument("--no-llm-evaluation", action="store_true",
                        help="Disable independent LLM evaluation (saves API costs)")
    parser.add_argument("--evaluator-model", type=str, default="openai/gpt-4o-mini",
                        help="Model for independent evaluation (default: openai/gpt-4o-mini)")
    parser.add_argument("--evaluator-provider", type=str, default="openrouter",
                        choices=["openrouter", "vllm"],
                        help="Provider for evaluator model (default: openrouter)")
    
    # Resource abundance options
    parser.add_argument("--initial-wealth-min", type=int, default=None,
                        help="Minimum initial sugar/spice per agent (default: 5)")
    parser.add_argument("--initial-wealth-max", type=int, default=None,
                        help="Maximum initial sugar/spice per agent (default: 25)")
    parser.add_argument("--growback-rate", type=int, default=None,
                        help="Resource growback rate per tick (higher = more abundant)")

    return parser.parse_args()


def parse_identity_distribution(dist_str: str) -> dict:
    """Parse identity distribution string like 'altruist:20,survivor:80' into dict."""
    if not dist_str:
        return None
    
    result = {}
    for item in dist_str.split(","):
        parts = item.strip().split(":")
        if len(parts) != 2:
            raise ValueError(f"Invalid identity distribution format: {item}. Expected 'type:percentage'")
        identity_type = parts[0].strip().lower()
        percentage = float(parts[1].strip()) / 100.0  # Convert percentage to fraction
        
        if identity_type not in ["altruist", "exploiter", "survivor"]:
            raise ValueError(f"Unknown identity type: {identity_type}. Valid: altruist, exploiter, survivor")
        
        result[identity_type] = percentage
    
    # Validate total sums to ~1.0
    total = sum(result.values())
    if abs(total - 1.0) > 0.01:
        raise ValueError(f"Identity distribution must sum to 100%, got {total*100:.1f}%")
    
    return result


def main():
    args = parse_args()

    # Handle smoke test - override settings for quick test
    if args.smoke_test:
        print("\n" + "="*60)
        print("SMOKE TEST MODE")
        print("="*60)
        args.ticks = 5
        args.population = 10
        args.width = 10
        args.height = 10
        args.single = "survival"
        print(f"Running quick test: {args.ticks} ticks, {args.population} agents on {args.width}x{args.height} grid")

    # Parse identity distribution if provided
    identity_distribution = None
    if args.identity_distribution:
        try:
            identity_distribution = parse_identity_distribution(args.identity_distribution)
            print(f"Custom identity distribution: {identity_distribution}")
        except ValueError as e:
            print(f"ERROR: {e}")
            sys.exit(1)

    # Determine model based on provider
    if args.provider == "vllm":
        model = args.model
        if args.lora:
            model = QWEN3_14B_LORA
        print(f"Using vLLM provider with model: {model}")
    else:
        # Check for API key
        if not os.environ.get("OPENROUTER_API_KEY"):
            print("ERROR: OPENROUTER_API_KEY environment variable not set!")
            print("Please export it: export OPENROUTER_API_KEY='sk-...'")
            sys.exit(1)
        model = args.model
        print(f"Using OpenRouter provider with model: {model}")

    if args.single:
        # Run single experiment
        trust_mode = args.trust_mechanism_mode
        if args.no_global_reputation:
            trust_mode = "personal_only"
        run_goal_experiment(args.single, args.ticks, args.seed, model,
                          args.population, args.width, args.height, args.difficulty,
                          args.trade_rounds, args.provider, args.lora,
                          args.use_mixed_identity, identity_distribution,
                          enable_survival_pressure=not args.no_survival_pressure,
                          social_memory_visible=not args.no_social_memory,
                          trust_mechanism_mode=trust_mode,
                          enable_abstraction_prompt=args.enable_abstraction_prompt,
                          encounter_protocol_mode=args.encounter_protocol_mode,
                          experiment_name_suffix=args.experiment_suffix,
                          enable_llm_evaluation=not args.no_llm_evaluation,
                          llm_evaluator_model=args.evaluator_model,
                          llm_evaluator_provider=args.evaluator_provider,
                          initial_wealth_min=args.initial_wealth_min,
                          initial_wealth_max=args.initial_wealth_max,
                          growback_rate=args.growback_rate)
    else:
        # Run comparison
        compare_goals(args.goals, args.ticks, args.seed, model,
                     args.population, args.width, args.height, args.difficulty,
                     args.trade_rounds, args.provider, args.lora)


if __name__ == "__main__":
    main()
